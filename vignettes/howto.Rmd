---
title: "Modeling Howto"
author: "Nils Kehrein"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
  github_document:
    toc: true
  word_document:
    toc: true
vignette: >
  %\VignetteIndexEntry{Modeling Howto}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  fig.path = "../doc/figures/howto-",
  comment = "#>"
)
```

```{r setup, include=FALSE}
library(cvasi)
```

This Howto provides instructions on how to address certain modeling challenges and
offers additional details and context for certain features of the package. A final 
section provides a complete worked out example.
For a more general overview, please refer to the [manual](manual.html).


## How to access scenario properties

The package provides a number of `set*()` functions to modify scenario
properties but generally no dedicated functions to inspect or retrieve
properties from a scenario object exist. Although these `get*()` are not
present, all scenario properties can be accessed at any time.

Scenario properties are stored in so-called *slots* within the scenario
objects. A *slot* is the name for an object attribute in *R*. The slots
of an object can be accessed by using the `@` operator. It behaves similar
to the `$` operator on named lists:


```{r}
# Create a new scenario object
myscenario <- Lemna_Schmitt()

# Access scenario slots and their default values
myscenario@name         # model name
myscenario@forcings.req   # forcings required for effect calculations
myscenario@endpoints    # available effect endpoints
myscenario@control.req  # are control runs required for effect calculation?
```

The previous example displays some of the default values of a
*Lemna_Schmitt* scenario. The set of available slots depends on the model
type and is documented in the package help. For instance, scenario
properties shared by all models are documented in the effect scenario
class:

  
```{r, eval=FALSE}
# Call the help page of effect scenarios class
?scenarios
```

A scenario class inherits all slots from its ancestors. A notable class
which modifies simulation behavior and provides additional scenario properties
is `Transferable`: it provides capabilities
to consider biomass transfers at defined time points during simulation.
Details about its class slots and functionality are described in the help pages.

```{r, eval=FALSE}
# Call the help page of the biomass transfer class
?Transferable
```

## Using *tidy* syntax

The tidy syntax, popularized by the tidyverse packages in R, provides a 
coherent and efficient approach to data manipulation and analysis. The tidyverse,
which includes, for example, the widely used dplyr and ggplot2 packages, follows a 
standardized grammar that makes the code more readable and intuitive. Tidy 
syntax emphasizes the use of functions with clear and descriptive names. This 
makes it easier for users to understand and reproduce analyses. The `%>%` (pipe) 
operator is a key component of tidy syntax and enables fluent and expressive
concatenation of operations. Overall, the introduction of 
tidy syntax in R improves code readability, reproducibility, and collaboration, 
resulting in maintainable data analysis pipelines.

In brief, the advantages of *tidy R* syntax are:

- a series of statements can be combined to an intuitive workflow using the
  pipeline (`%>%`) operator
- a short cut for the pipe (`%>%`) operator is Ctrl+Shift+M
- pipelines reduce the need for intermediary variables (but thoughtful intermediates are recommended)
- *tidy* verbs generally take `list` data types as input and return these also as output
- some verbs enrich outputs with additional information, effectively extending
  the output data to a table

```{r, eval=FALSE}
# Create the results of a control run for an existing Lemna model called 
# metsulfuron with a starting biomass value of 50, which corresponds to 
# 50000 fronds.
  metsulfuron %>%
    set_noexposure() %>%  # set no exposure (i.e., a control run)
    set_init(c(BM = 50)) %>%  # set initial biomass
    simulate()
```

## Predictions

TKTD models have both species and substance specificity. If risks are identified
at Tier 1 (standard test species approach) and exposure duration is expected to 
be shorter than in standard tests, the simplest solution is to develop TKTD 
models for standard test species. However, if Tier 2A (geometric mean/evidence 
weighting approach) or Tier 2B (species sensitivity distribution approach) 
information is available, it may be more appropriate to develop TKTD models for 
a wider range of species to increase the accuracy of the risk assessment. 
Validated TKTD models for these different species can be used as an alternative 
to assess specific risks using available field exposure profiles. This includes 
the calculation of exposure profile specific LPx/EPx values (multiplication 
factor for a specific overall exposure profile causing x % lethality or effect) 
based on an appropriate aquatic exposure assessment.

```{r, eval=FALSE}
# Calculation of EPx values for a complete concentration profile.
  set.seed(123)  # Setting a seed for reproducibility
# Generating a random profile for 15 days with concentrations below 0.1
  random_conc <- runif(15, min=0, max=0.1)
  exposure_profile <- data.frame(t=0:14, c=random_conc)
# run EPx calculations for full exposure profile
  metsulfuron %>%
    set_exposure(exposure_profile) %>%  # set a specific exposure scenario
    epx()  # run EPx calculations
```

## Moving exposure windows

A moving time window is a computing technique used in data analysis. Data is 
systematically analysed within a window of fixed size that moves or slides 
through the data set in our case an exposure profile. The window captures a 
subset of successive data points, and as it moves through the data, calculations
are performed in each window.

```{r, eval=FALSE}
# Calculation of EPx values for a complete concentration profile.
set.seed(123)  # Setting a seed for reproducibility
# Generating a random profile for 15 days with concentrations below 0.1
random_conc <- runif(15, min = 0, max = 0.1)
exposure_profile <- data.frame(time = 0:14, conc = random_conc)

# run EPx calculations for a window length of 7 days and a step size of 1
metsulfuron_epx_mtw <- metsulfuron %>%
  set_exposure(exposure_profile) %>%
  epx_mtw(window_length = 7, 
          window_interval = 1, 
          level = c(10))
metsulfuron_epx_mtw

# The result can be plotted with plot_EPx()
plot_epx(metsulfuron_epx_mtw, exposure_profile)

```

`effect()` can report effect levels for all evaluated exposure windows
on demand:

```{r, eval=FALSE}
# Derive effect levels of all exposure windows
metsulfuron %>% effect(max_only=FALSE)

```

The resulting table describes how effect levels change when the exposure
window moves along the exposure series. It is also possible to specify the marginal
effect threshold of reported results (this prevents overinterpretation of spurious 
effect levels originating from minuscule numerical errors introduced during 
simulation), as in the following example:


```{r, eval=FALSE}
# Only report effect levels larger than 1e-5 = 0.001%
metsulfuron %>% effect(max_only=FALSE, marginal_effect=1e-5)
```

## Simulating biomass transfers

A transfer refers to an event where a certain amount of biomass (BM) is moved to
a new medium after a period of time. This feature replicates a procedure 
occurring e.g. in *Lemna* effect studies and may be necessary to recreate study 
results. At each transfer, a defined amount of biomass is transferred to a new 
medium. This is modeled by interrupting the simulation at a transfer time point, 
modifying the biomass level BM, and scaling affected compartments according to 
new biomass levels. Scaling of compartments depending on biomass, such as 
internal toxicant mass, is necessary to correctly reflect mass balances and 
concentrations over time.

Option 1: regular intervals
```{r, eval=FALSE}
  metsulfuron %>%
    set_init(c(BM=1)) %>%
    set_noexposure() %>%
    set_transfer(interval=3, biomass=1) %>%
    simulate()
```

Option 2: custom time points and custom biomass
```{r, eval=FALSE}
  metsulfuron %>%
    set_init(c(BM=1)) %>%
    set_noexposure() %>%
    set_transfer(times=c(3,6), biomass=c(1,0.5)) %>%
    simulate()
```

```{r, eval=FALSE}
# Call the help page of set_transfer
?set_transfer
```

## Fitting model parameters

Parameters of a model can be fitted (calibrated) against observed effect data.

The calibration routines are not yet par of the package, but can be downloaded
from Github.

The current workflow for calibration is:

1. Combine the necessary inputs (model, exposure scenario, effect data).
2. Fit the model for the given exposure scenario(s) and corresponding 
effect dataset(s).

For the first step, two options are available:

* When only one exposure level (e.g., one experimental treatment) and 
corresponding effect dataset (effect data only contain observations corresponding 
to one exposure scenario) are of interest, then the `EffectScenario` (which 
includes the model and one exposure scenario) and the effect data can directly 
be entered into the `calibrate()` function. 

* Alternatively, one can combine the `EffectScenario` and effect data into
a `CalibrationSet` object first using the `CalibrationSet()` function, and 
subsequently do the fitting of the model using the `calibrate()` function with 
one or more `CalibrationSet` objects (organised into a list) as input.

After calibration, one can, for example, inspect the updated parameter values, 
simulate with the updated model, and plot results of these new simulations

```{r, eval=FALSE}
# Create Effect Scenario
# Get exposure data in the highest treatment level of the Schmitt 2013 study
exp_df <- Schmitt2013 %>%
  dplyr::filter(ID == "T5.6") %>%
  dplyr::select(t, conc)
# Create exposure scenario containing the exposure data in the highest treatment level
exp_scen <- metsulfuron %>%
  set_exposure(exp_df)
# Get corresponding effect data from the Schmitt 2013 study
# Observed effects in the highest treatment level
eff_df <- Schmitt2013 %>%
  dplyr::filter(ID == "T5.6") %>%
  dplyr::select(t, obs)
```

Option 1: direct calibration with 1 EffectScenario + 1 effect dataset

```{r, eval=FALSE}
# Option 1: direct calibration with 1 EffectScenario + 1 effect dataset
fit1 <- calibrate(
  x = exp_scen,  # exposure scenario containing the exposure of the Schmitt 2013 study 
  par = c(k_phot_max = 1, k_resp = 0.1),
  data = eff_df, # observed effect data from the Schmitt 2013 study
  endpoint = "BM"
)
fit1$par
# Update exposure scenario  with new parameter values
metsulfuron2 <- metsulfuron %>%
  set_param(fit1$par)
# Look at new parameters of the exposure scenario
metsulfuron2@param$k_phot_max
metsulfuron2@param$k_resp
# simulate with updated model
# treatments in long format
treatments <- data.frame(time = Schmitt2013$t,
                         trial = Schmitt2013$ID,
                         conc = Schmitt2013$conc)
rs_mean <- simulate_batch(
  model_base = metsulfuron2,
  treatments = treatments,
  param_sample = NULL
)
# observations in long format
obs_mean <- data.frame(time = Schmitt2013$t,
                       trial = Schmitt2013$ID,
                       data = Schmitt2013$obs)
# plot results
plot_sd(
  model_base = metsulfuron2,
  treatments = treatments,
  rs_mean = rs_mean,
  obs_mean = obs_mean
)
```

Option 2: create `CalibrationSet` before calibration, and then calibrate on a
list of `CalibrationSets` Create list of CalibrationSets

```{r, eval=FALSE}
# get all the exposure scenarios from the Schmitt 2013 study
library(dplyr)
Schmitt2013 %>%
  group_by(ID) %>%
  group_map(function(data, key) {
    exp <- data %>% select(t, conc)
    obs <- data %>% select(t, obs)
    sc <- metsulfuron %>% set_exposure(exp)
    CalibrationSet(sc, obs)
  }) -> cs

# Calibrate
fit2 <- calibrate(
  cs,
  par=c(k_phot_max=5, k_resp=0.8),
  endpoint="BM"
)
fit2
```

## Changes in parameter values over time

`sequence()` creates an object which will represent a sequence of several
scenarios. The sequence is treated as a single scenario and each scenario is
simulated one after the other. Scenario sequences can be used to e.g. implement
changes in model parameters over time.

Sequences can be used to represent changing conditions over time, such as a
change in model parameters which would otherwise be constant. This can be
used to represent events such as a pump failure or change in temperature.

```{r}
# base scenario only valid until day 7
sc1 <- metsulfuron %>%
  set_times(0:7)

# a parameter change occurs at day 7: global radiation decreases to 8,000 kJ/m2/d
sc2 <- metsulfuron %>%
  set_times(7:14) %>%
  set_forcings(rad=8000)
 
seq <- sequence(list(sc1, sc2))
simulate(seq)
```

```{r, eval=FALSE}
# Call the help page of `sequence`
?sequence
```

## Decrease assessment runtime

There are ways to decrease the runtime of a simulation. One possibility 
is to reduce the maximum step length of the solver by setting the 
optional argument `hmax`. The larger `hmax`, the faster the simulations. 
But be careful, the larger hmax, the greater the risk that the results will be 
inaccurate.

Especially for the simulation of long periods of time, such as annual exposure 
profiles, the results may be inaccurate. Oftentimes, it will be computational 
more efficient to adapt the solver's error tolerances `atol` and `rtol` than 
reducing the step width `hmax` to achieve stable numerics. Start by decreasing 
deSolve's default values by orders of ten until the simulation yields
acceptable results, see e.g. ?deSolve::lsoda() for more information on error 
tolerances.

```{r}
# Simulations with a maximum solver step length of hmax=0.01
metsulfuron %>%
  set_times(0:7) %>%
  simulate(hmax=0.1)
```

## Implementing custom models

The set of supported models can be extended as needed.
Additional models can be added to the package itself if they are considered
mature and are not expected to evolve over time. By contrast, experimental
or one-time use models can be implemented in a user's script and inserted
into the package's workflow as well.

The starting point to add a new model is an implementation of the model's
rules and dynamics in *R* code. In most cases, this will be a code snippet
which describes the model's Ordinary Differential Equations (ODE):

```{r, warning=FALSE}
## An exemplary implementation of the GUTS-RED-SD TKTD model ##
# Model ODEs following the deSolve specification
sd_ode <- function(t, state, params) {
  with(as.list(c(state, params)), {
    dDw <- kd * (Cw(t) - Dw)            # dDw/dt, scaled damage
    dH <- kk * max(0, Dw - z)           # dH/dt, cumulative hazard
    
    list(c(dDw, dH))                    # return derivatives
  })
}
```

The previous example implements the model equations in a way that
can be processed by the `deSolve` package for numerical integration. For a
detailed description on how to use `deSolve`, please refer to its vignette:

```{r, eval=FALSE}
vignette("deSolve", package="deSolve")
```

With some additional scenario data such as initial state, output
time points, and model parameters, we are able to simulate our custom
TKTD model:

```{r, warning=FALSE}
## Properties of a sample scenario ##
init <- c(Dw=0, H=0)                         # initial state
times <- 0:5                                 # output time points [0,5]
param <- c(kd=22, hb=0.01, z=0.5, kk=0.08)   # model parameters
exp <- data.frame(time=0:5,                  # exposure time-series
                  conc=c(0,1,1,0.5,0.6,0.2))

# Create a linear interpolation of the exposure time-series
expf <- approxfun(x=exp$time, y=exp$conc, method="linear", rule=2)
# Extend parameter set by interpolated exposure series
paramx <- as.list(c(param, Cw=expf))

# Numerically solve the ODE
deSolve::ode(y=init, times=times, parms=paramx, func=sd_ode)
```

When we have made sure that our custom model can be simulated and works as expected,
we can continue with integrating it into the package's workflow. First, we will
define a new scenario class that identifies our custom model by a unique name.
Next, we have to tell the package how the models of this class can be simulated.
In a final step, we may have to describe how effects are calculated for these
models.

We start by defining a new scenario class that derives from a suitable ancestor.
In general, we can inherit from the base class `EffectScenario` which
provides the general scenario capabilities. However, if the
custom model is just a variant of an existing model category, then it will be
easier to derive from specialized scenario class that already provides certain
features such as effect calculation. The following
class tree gives an overview of the scenario classes in use:

    EffectScenario
    |    
    |   Transferable
    |___|__ Lemna
    |   |   |__ LemnaSchmittScenario
    |   |   |__ LemnaSetacScenario
    |   |
    |   |__ Myriophyllum
    |   |   |__ MyrioExpScenario
    |   |   |__ MyrioLogScenario
    |   |
    |   |__ Algae
    |       |__ AlgaeWeberScenario
    |       |__ AlgaeTKTDScenario
    |       |__ AlgaeSimpleScenario    
    |
    |__ GutsRedSd
    |__ GutsRedIt
    |
    |__ DebScenario
        |__ DebAbj
        |__ DebDaphnia

To give an example, to implement a variant of a *Lemna* model, it would be advisable
to derive from the class `Lemna` to benefit from already implemented features
such as effect endpoint calculation and simulation of biomass transfers.
For the custom GUTS-RED-SD model, the ideal choice would be to derive from
`GutsRedSd` to minimize the implementation overhead. However, we will
derive from the general `EffectScenario` class for the sake of our example and
create a scenario object:

```{r}
## Integrate a new model class into the package workflow ##
# Create a unique class that derives from 'EffectScenario'
setClass("MyGuts", contains="EffectScenario")

# Create an object of the new class and assign scenario properties
new("MyGuts", name="My custom model") %>%
  set_init(init) %>%
  set_times(times) %>%
  set_param(param) %>%
  set_exposure(exp, reset_times=FALSE) %>%
  set_endpoints("L") -> myscenario

myscenario
```

The object `myscenario` now carries all the settings and data which we also
used for our test simulation. In the next step, the `solver()` function will
be overloaded to handle objects
of the newly defined scenario class `MyGuts`. The adapted `solver()` function will
collect the properties of a given scenario object, call the ODE solver, and return
simulation results:

```{r}
# the actual function calling deSolve can have a different signature
solver_myguts <- function(scenario, times, ...) {
  # overriding output times by function argument must be possible
  if(missing(times))
    times <- scenario@times
  
  # get relevant data from scenario
  init <- scenario@init
  param <- scenario@param
  exp <- scenario@exposure@series
  if(nrow(exp) == 1) { # extend exposure series to have at least two rows
    row2 <- exp[1,]
    row2[[1]] <- row2[[1]]+1
    exp <- rbind(exp, row2)
  }
  
  # Create a linear interpolation of the exposure time-series
  expf <- approxfun(x=exp[,1], y=exp[,2], method="linear", rule=2)
  # Extend parameter set by interpolated exposure series
  paramx <- as.list(c(param, Cw=expf))
  
  as.data.frame(deSolve::ode(y=init, times=times, parms=paramx, func=sd_ode, ...))
}

## Overload the simulate() function ##
# The functions signature, i.e. the number and names of its arguments, must stay as is
setMethod("solver", "MyGuts", function(scenario, times, ...) solver_myguts(scenario, times, ...))
```

Overloading an *S4* function is done using `setMethod()`. The first argument
to `setMethod()` identifies which function we want to overload, in this case it is
`solver`. The second argument, `MyGuts`, defines which object type our
overloaded function will accept. In this case, we want to provide an implementation
to simulate `MyGuts` scenarios. *R* will decide during runtime which of the
function candidates to execute when `solver()` is called based on the type
of the first argument to `solver()`. The third argument, `function(object, ...) solver_myguts(scenario=object, ...)`
forwards calls to an appropriate function which can handle
`MyGuts` objects. The function signature `function(object, ...)` must stay exactly 
as it is and must not be modified.

The code within the body of `solver_myguts()` is almost identical to the original
code used to simulate the prototyped model. We have to deal with one corner
case, though: some exposure time-series will contain only a single row, representing
constant exposure over time, but this would raise an error in `approxfun()`.
In order to avoid this error, we will duplicate the first row and append it to
the series. Technically, this issue should be handled in the prototyped code as
well but was left out for reasons of brevity.

The parameterized scenario object `myscenario` of class `MyGuts` can be
passed to the overloaded `simulate()` function:

```{r}
myscenario %>% simulate()
```


The custom model can now be simulated using the framework but it is still
missing effect endpoints. If, on the other hand, we had decided to inherit our
scenario class from a suitable ancestor, such as `GutsRedSd`, we could
have stopped at this point as the ancestor would provide routines to calculate
effects.

By default, any state variable is available
as an effect endpoint and the calculated effect would reflect the change in the
state variables' value at the end of the simulation. However, we need to
calculate the *survival* endpoint in a different manner for GUTS-RED type models.
To implement this specialized endpoint, we need to overload the
function `fx()` which calculates effect endpoints:

```{r}
## Overload effect endpoint calculation ##
# fx() is called by effect()
setMethod("fx", "MyGuts", function(scenario, ...) fx_myguts(scenario, ...))

# @param scenario Scenario object to assess
# @param window Start & end time of the moving exposure window
# @param ... any additional parameters
fx_myguts <- function(scenario, window, ...) {
  # simulate the scenario (it is already clipped to the moving exposure window)
  out <- simulate(scenario, ...)
  # only use model state at the end of the simulation
  out <- tail(out, 1)
  # calculate survival according to EFSA Scientific Opinion on TKTD models
  # p. 33, doi:10.2903/j.efsa.2018.5377
  t <- unname(window[2] - window[1])
  survival <- exp(-out$H) * exp(-scenario@param$hb * t)
  return(c("L"=survival))
}

# Derive effect levels for our sample scenario
myscenario %>% effect()
```

`fx()` is used by `effect()` to derive effect endpoints for each model.
By convention, any overload of the `fx()` function must return a named
numerical vector containing the effect endpoints for the provided scenario
and moving exposure window. The scenario will already be parameterized to
only simulate the current exposure window. The return value of `fx()` will then
be used to calculate effect levels. In case of models requiring a control
scenario, the effect level will be calculated as `1 - effect/control`. For models not
requiring a control, the overloaded `fx()` must return the final effect
level, i.e. a value from the interval `[0,1]` (0% to 100% effect).


## Complete working example

In this section, a complete example is given to make predictions and 
evaluate toxic effects using a calibrated model, as might be conducted in a risk
assessment context. Specifically, the 
*Lemna* model will be set up to match the study of
Schmitt et al. (2003, doi: 10.1016/j.ecolmodel.2013.01.017) who exposed *Lemna*
to metsulfuron-methyl.

The model will be parameterized with the values as described in the study. Then,
the model will be inspected and used to make predictions for 
exposure scenarios, plot results, and get EPx calculations.


### Setting up a scenario
Setting up the model (i.e. creating an `EffectScenario`) involved defining the parameters,
the environmental variables (external forcings and chemical exposure), and the initial
conditions. Further, a tag can be given to easily identify and retrieve the 
`EffectScenario` by name. Also, for primary producer models, a transfer of biomass
can be defined matching with the experimental design of the study.

```{r}
## Get all model parameters
# algae model parameters taken from file 'mm2.r' included
# in supporting material of Schmitt et al. (2013)
param_study <- list(
  #     - Effect -
  Emax     = 0.784,   # [same as conc. data]  maximum effect concentration
  EC50     = 0.3,     # [same as conc. data]  Midpoint of effect curve
  b        = 4.16,    # [-]  Slope of effect curve
  #     - Toxicokinetics -
  P_up     = 0.0054,  # [cm/d]  Permeability for uptake
  AperBM   = 1000,    # [cm^2/g_dw]  Frond area/dry weight
  Kbm      = 0.75,    # []  Biomass(fw)-water partition coefficient
  P_Temp   = F,       # Switch for temperature dependence of cuticle permeability
  MolWeight = 381,    # [g/mol] Molmass of molecule (determines Q10_permeability)
  #     - Fate of biomass -
  k_phot_fix  = F,    # If True k_G_max is not changed by environmental factors
  k_phot_max  = 0.47, # [1/d]  Maximum photosynthesis rate
  k_resp   = 0.05,    # [1/d]  Respiration rate at ref. temperature
  k_loss   = 0.0,     # [1/d]  Some rate of loss (e.g. Flow rate)
  #     - Temperature dependence -
  Tmin     = 8.0  ,   # [°C]  Minimum growth temperature 
  Tmax     = 40.5 ,   # [°C]  Maximum growth temperature
  Topt     = 26.7 ,   # [°C]  Optimum growth temperature 
  t_ref    = 25,      # [°C]  Reference temperature for respiration rate
  Q10      = 2,       # [-]   Temperature dependent factor for respiration rate
  #     - Light dependence (Linear) -
  k_0      = 3 ,      # [1/d]  Intercept of linear part
  a_k      = 5E-5 ,   # [(1/d)/(kJ/m^2/d)]   Slope of linear part
  #     - Phosphorus dependence (Hill like dependence) -
  C_P      = 0.3,     # [mg/L]  Phosporus concentration in water
  CP50     = 0.0043,  # [mg/L]  P-conc. where growth rate is half
  a_P      = 1,       # []  Hill coefficient
  KiP      = 101,     # [mg/L]  P-inhibition constant for very high P-conc.
  #     - Nitrogen dependence (Hill like dependence) -
  C_N      = 0.6,     # [mg/L]  Nitrogen concentration in water
  CN50     = 0.034,   # [mg/L]  N-conc. where growth rate is half
  a_N      = 1,       # []  Hill coefficient
  KiN      = 604,     # [mg/L]  n-inhibition constant for very high P-conc.
  #     - Density dependence -
  BM50     = 176,     # [g_dw/m^2] Cut off BM
  #     - Others -
  mass_per_frond = 0.0001,  # [g_dw/frond]  Dry weight per frond
  BMw2BMd  = 16.7     # [g_fresh/g_dry]  Fresh- / dryweight 
)


## Define the forcing variables
forc_temp <- data.frame(t = 0, tmp = 12) # [°C]  Current temperature (may also be a table)
forc_rad  <- data.frame(t = 0, rad = 15000) # [kJ/m²/d]  Radiation  (may also be given as table)


## Define a simple exposure pattern
# t 0..6  concentration 1 ug/L
# t 7..14 concentration 0 ug/L
exposure <- data.frame(time = 0:14, 
                       conc = c(rep(1, 7), rep(0, 8))
                       )


## Set initial values 
# given in file 'mmc2.r' of Schmitt et al. (2013)
init <- c(
  BM       = 50,     # [g_dw/m^2]  Dry Biomass dry weight per m2
  E        = 1,      # (0-1)  (Toxic) Effect = Factor on growth rate  (Range: 0 - 1, 1=no effect)
  M_int    = 0       # [ug]   Amount of toxicant in biomass
)

## create an EffectScenario object, containing the model (with parameters) and the exposure scenario
Lemna_Schmitt() %>%               # the Lemna model
  set_tag("metsulfuron") %>%      # set a tage for the specific implementation of the model
  set_init(init) %>%              # set the starting values (as prepared above)
  set_param(param_study) %>%      # set the parameters (as prepared above)
  set_exposure(exposure) %>%      # set the exposure scenario (exposure time series)
  set_forcings(temp=forc_temp, rad=forc_rad) -> metsulfuron # set the external forcing 
# variables, and save everything as an object


```


### Simulating a scenario and plotting

```{r out.width = "75%"}
## simulate with model, under a range of different exposure scenarios
# create several exposure scenarios
exp_scen <- data.frame(time = Schmitt2013$t,
                       trial = Schmitt2013$ID,
                       conc = Schmitt2013$conc)
# simulate for all these scenarios
results <- simulate_batch(
  model_base = metsulfuron,
  treatments = exp_scen,
  param_sample = NULL
)
# plot results
plot_sd(
  model_base = metsulfuron,
  treatments = exp_scen,
  rs_mean = results,
)


## simulate with model, under a range of different exposure scenarios, and including 
## a biomass transfer
# simulate for all scenarios
results <- metsulfuron %>%
  set_transfer(interval = c(5), biomass = 10) %>% # implement a biomass transfer every 5 days
  simulate_batch(treatments = exp_scen)
# plot results
plot_sd(
  model_base = metsulfuron,
  treatments = exp_scen,
  rs_mean = results,
)

```

